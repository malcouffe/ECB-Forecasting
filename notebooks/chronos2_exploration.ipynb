{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploration du mod√®le Chronos-2\n",
        "\n",
        "Ce notebook permet d'explorer la structure du mod√®le Chronos-2 depuis Hugging Face.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation et imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration SSL pour macOS\n",
        "import ssl\n",
        "import certifi\n",
        "\n",
        "# Utiliser les certificats de certifi\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "print(\"‚úì Configuration SSL appliqu√©e\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoModel, AutoConfig\n",
        "from huggingface_hub import list_repo_files, model_info\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. √Ä propos de Chronos-2\n",
        "\n",
        "**Chronos-2** est un mod√®le de fondation pour la pr√©vision de s√©ries temporelles d√©velopp√© par Amazon. \n",
        "\n",
        "Il supporte :\n",
        "- Pr√©visions **univari√©es** (une seule s√©rie)\n",
        "- Pr√©visions **multivari√©es** (plusieurs s√©ries simultan√©ment)\n",
        "- Pr√©visions **inform√©es par des covariables** (variables externes)\n",
        "\n",
        "Tout cela dans une architecture unique et unifi√©e !\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utiliser le mod√®le Chronos-2 officiel\n",
        "model_name = \"amazon/chronos-2\"\n",
        "\n",
        "print(f\"Mod√®le s√©lectionn√©: {model_name}\")\n",
        "print(\"Chronos-2 est la derni√®re version du mod√®le Amazon pour la pr√©vision de s√©ries temporelles\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Informations sur le mod√®le depuis Hugging Face\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# R√©cup√©rer les informations du mod√®le\n",
        "info = model_info(model_name)\n",
        "\n",
        "print(f\"Nom du mod√®le: {info.modelId}\")\n",
        "print(f\"Auteur: {info.author}\")\n",
        "print(f\"Tags: {info.tags}\")\n",
        "print(f\"Pipeline: {info.pipeline_tag}\")\n",
        "print(f\"Derni√®re modification: {info.lastModified}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lister les fichiers du repository\n",
        "files = list_repo_files(model_name)\n",
        "print(\"\\nFichiers dans le repository:\")\n",
        "for file in files:\n",
        "    print(f\"  - {file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Chargement de la configuration du mod√®le\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger la configuration sans t√©l√©charger les poids\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "\n",
        "print(\"Configuration du mod√®le:\")\n",
        "print(f\"  - Architecture: {config.model_type}\")\n",
        "print(f\"  - Nombre de couches: {config.num_layers}\")\n",
        "print(f\"  - Nombre de t√™tes d'attention: {config.num_heads}\")\n",
        "print(f\"  - Dimension du mod√®le: {config.d_model}\")\n",
        "print(f\"  - Dimension FFN: {config.d_ff}\")\n",
        "print(f\"  - Taille du vocabulaire: {config.vocab_size}\")\n",
        "print(f\"  - Longueur max: {config.n_positions if hasattr(config, 'n_positions') else 'N/A'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Afficher toute la configuration\n",
        "print(\"\\nConfiguration compl√®te:\")\n",
        "print(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. T√©l√©chargement et chargement du mod√®le\n",
        "\n",
        "**Attention**: Le t√©l√©chargement peut prendre du temps selon la taille du mod√®le et votre connexion internet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger le mod√®le Chronos-2 avec la bonne classe\n",
        "from chronos import Chronos2Pipeline\n",
        "\n",
        "print(\"T√©l√©chargement du mod√®le Chronos-2 en cours...\")\n",
        "print(\"Note: Le t√©l√©chargement peut prendre plusieurs minutes...\")\n",
        "\n",
        "# Utiliser Chronos2Pipeline au lieu de AutoModel pour charger correctement les poids\n",
        "pipeline = Chronos2Pipeline.from_pretrained(\n",
        "    model_name, \n",
        "    device_map=\"mps\",  # \"mps\" pour Apple Silicon, \"cuda\" pour GPU NVIDIA, \"cpu\" pour CPU\n",
        "    torch_dtype=\"auto\"\n",
        ")\n",
        "print(\"Mod√®le Chronos-2 charg√© avec succ√®s!\")\n",
        "print(f\"Device utilis√©: {pipeline.model.device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Exploration de la structure du mod√®le\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Afficher l'architecture du mod√®le\n",
        "print(\"Architecture du mod√®le:\")\n",
        "print(pipeline.model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compter les param√®tres\n",
        "def count_parameters(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return total_params, trainable_params\n",
        "\n",
        "# Acc√©der au mod√®le T5 sous-jacent dans le pipeline\n",
        "total, trainable = count_parameters(pipeline.model)\n",
        "print(f\"\\nNombre total de param√®tres: {total:,}\")\n",
        "print(f\"Param√®tres entra√Ænables: {trainable:,}\")\n",
        "print(f\"Taille approximative en m√©moire: {total * 4 / (1024**2):.2f} MB (float32)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lister tous les modules du mod√®le\n",
        "print(\"\\nModules principaux:\")\n",
        "for name, module in pipeline.model.named_children():\n",
        "    print(f\"  - {name}: {type(module).__name__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explorer les couches en d√©tail\n",
        "print(\"\\nCouches du mod√®le (premier niveau):\")\n",
        "for name, param in pipeline.model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"  - {name}: {param.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Analyse des composants cl√©s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyser l'encoder\n",
        "if hasattr(pipeline.model, 'encoder'):\n",
        "    print(\"Structure de l'Encoder:\")\n",
        "    print(pipeline.model.encoder)\n",
        "    print(f\"\\nNombre de couches dans l'encoder: {len(list(pipeline.model.encoder.children()))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyser le decoder\n",
        "if hasattr(pipeline.model, 'decoder'):\n",
        "    print(\"Structure du Decoder:\")\n",
        "    print(pipeline.model.decoder)\n",
        "    print(f\"\\nNombre de couches dans le decoder: {len(list(pipeline.model.decoder.children()))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Exemple d'utilisation de Chronos-2 pour la pr√©vision\n",
        "\n",
        "Voici comment utiliser Chronos-2 pour faire des pr√©visions sur vos propres donn√©es.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd  # requires: pip install 'pandas[pyarrow]'\n",
        "from chronos import Chronos2Pipeline\n",
        "\n",
        "pipeline = Chronos2Pipeline.from_pretrained(\"amazon/chronos-2\", device_map=\"mps\")\n",
        "\n",
        "# Load historical target values and past values of covariates\n",
        "context_df = pd.read_parquet(\"https://autogluon.s3.amazonaws.com/datasets/timeseries/electricity_price/train.parquet\")\n",
        "\n",
        "# (Optional) Load future values of covariates\n",
        "test_df = pd.read_parquet(\"https://autogluon.s3.amazonaws.com/datasets/timeseries/electricity_price/test.parquet\")\n",
        "future_df = test_df.drop(columns=\"target\")\n",
        "\n",
        "# Generate predictions with covariates\n",
        "pred_df = pipeline.predict_df(\n",
        "    context_df,\n",
        "    future_df=future_df,\n",
        "    prediction_length=24,  # Number of steps to forecast\n",
        "    quantile_levels=[0.1, 0.5, 0.9],  # Quantiles for probabilistic forecast\n",
        "    id_column=\"id\",  # Column identifying different time series\n",
        "    timestamp_column=\"timestamp\",  # Column with datetime information\n",
        "    target=\"target\",  # Column(s) with time series values to predict\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Param√®tres d'inf√©rence du Chronos2Pipeline\n",
        "\n",
        "Explorons les param√®tres disponibles pour l'inf√©rence avec Chronos-2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examiner la signature de la m√©thode predict_df\n",
        "import inspect\n",
        "\n",
        "print(\"=== Signature de predict_df ===\\n\")\n",
        "print(inspect.signature(pipeline.predict_df))\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Afficher la documentation compl√®te\n",
        "print(\"=== Documentation de predict_df ===\\n\")\n",
        "print(pipeline.predict_df.__doc__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examiner aussi la m√©thode predict (pour les arrays numpy/tensors)\n",
        "print(\"=== Signature de predict ===\\n\")\n",
        "print(inspect.signature(pipeline.predict))\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "print(\"=== Documentation de predict ===\\n\")\n",
        "print(pipeline.predict.__doc__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Exemple d'inf√©rence avec param√®tres personnalis√©s\n",
        "\n",
        "Voici comment utiliser les diff√©rents param√®tres d'inf√©rence disponibles dans Chronos-2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cr√©er des donn√©es de test simples\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Cr√©er une s√©rie temporelle simple pour tester\n",
        "dates = pd.date_range(start='2024-01-01', periods=100, freq='D')\n",
        "values = np.sin(np.linspace(0, 4*np.pi, 100)) + np.random.normal(0, 0.1, 100)\n",
        "\n",
        "# Cr√©er un DataFrame de contexte\n",
        "simple_context_df = pd.DataFrame({\n",
        "    'id': ['series_1'] * 100,\n",
        "    'timestamp': dates,\n",
        "    'target': values\n",
        "})\n",
        "\n",
        "print(\"Donn√©es de test cr√©√©es:\")\n",
        "print(simple_context_df.head())\n",
        "print(f\"\\nTaille: {len(simple_context_df)} observations\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 1: Inf√©rence avec param√®tres par d√©faut\n",
        "print(\"=== Inf√©rence avec param√®tres par d√©faut ===\\n\")\n",
        "\n",
        "pred_default = pipeline.predict_df(\n",
        "    simple_context_df,\n",
        "    prediction_length=10,  # Nombre de pas de temps √† pr√©dire\n",
        "    id_column=\"id\",\n",
        "    timestamp_column=\"timestamp\",\n",
        "    target=\"target\"\n",
        ")\n",
        "\n",
        "print(pred_default.head(15))\n",
        "print(f\"\\nShape: {pred_default.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 2: Inf√©rence avec quantiles sp√©cifiques\n",
        "print(\"=== Inf√©rence avec quantiles personnalis√©s ===\\n\")\n",
        "\n",
        "pred_quantiles = pipeline.predict_df(\n",
        "    simple_context_df,\n",
        "    prediction_length=10,\n",
        "    quantile_levels=[0.05, 0.25, 0.5, 0.75, 0.95],  # Quantiles pour intervalles de confiance\n",
        "    id_column=\"id\",\n",
        "    timestamp_column=\"timestamp\",\n",
        "    target=\"target\"\n",
        ")\n",
        "\n",
        "print(pred_quantiles.head(15))\n",
        "print(f\"\\nColonnes disponibles: {pred_quantiles.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiser les pr√©dictions avec intervalles de confiance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Afficher les donn√©es historiques\n",
        "ax.plot(simple_context_df['timestamp'], simple_context_df['target'], \n",
        "        label='Donn√©es historiques', linewidth=2, color='blue')\n",
        "\n",
        "# Extraire les pr√©dictions\n",
        "pred_filtered = pred_quantiles[pred_quantiles['id'] == 'series_1']\n",
        "\n",
        "# Afficher la m√©diane (quantile 0.5)\n",
        "if '0.5' in pred_filtered.columns:\n",
        "    ax.plot(pred_filtered['timestamp'], pred_filtered['0.5'], \n",
        "            label='Pr√©diction (m√©diane)', linewidth=2, color='red', linestyle='--')\n",
        "\n",
        "# Afficher les intervalles de confiance\n",
        "if '0.05' in pred_filtered.columns and '0.95' in pred_filtered.columns:\n",
        "    ax.fill_between(pred_filtered['timestamp'], \n",
        "                     pred_filtered['0.05'], \n",
        "                     pred_filtered['0.95'],\n",
        "                     alpha=0.2, color='red', label='IC 90%')\n",
        "\n",
        "if '0.25' in pred_filtered.columns and '0.75' in pred_filtered.columns:\n",
        "    ax.fill_between(pred_filtered['timestamp'], \n",
        "                     pred_filtered['0.25'], \n",
        "                     pred_filtered['0.75'],\n",
        "                     alpha=0.3, color='red', label='IC 50%')\n",
        "\n",
        "ax.set_xlabel('Date', fontsize=12)\n",
        "ax.set_ylabel('Valeur', fontsize=12)\n",
        "ax.set_title('Pr√©visions Chronos-2 avec intervalles de confiance', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Param√®tres avanc√©s d'inf√©rence\n",
        "\n",
        "Les param√®tres principaux disponibles pour l'inf√©rence avec Chronos-2 incluent g√©n√©ralement :\n",
        "\n",
        "- **`prediction_length`**: Nombre de pas de temps √† pr√©dire\n",
        "- **`quantile_levels`**: Liste des quantiles pour les pr√©visions probabilistes (ex: [0.1, 0.5, 0.9])\n",
        "- **`num_samples`**: Nombre d'√©chantillons √† g√©n√©rer pour les pr√©visions probabilistes\n",
        "- **`temperature`**: Contr√¥le la diversit√© des pr√©dictions (plus √©lev√© = plus de variance)\n",
        "- **`top_k`**: Consid√®re uniquement les k tokens les plus probables\n",
        "- **`top_p`**: √âchantillonnage nucleus (consid√®re les tokens dont la prob cumul√©e < p)\n",
        "- **`batch_size`**: Taille des lots pour le traitement\n",
        "- **`limit_prediction_length`**: Limite la longueur maximale des pr√©dictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 3: Exploration des param√®tres disponibles dans le pipeline\n",
        "print(\"=== Attributs du pipeline ===\\n\")\n",
        "\n",
        "# Afficher les attributs principaux du pipeline\n",
        "if hasattr(pipeline, '__dict__'):\n",
        "    print(\"Attributs disponibles:\")\n",
        "    for key, value in pipeline.__dict__.items():\n",
        "        if not key.startswith('_'):\n",
        "            print(f\"  - {key}: {type(value).__name__}\")\n",
        "\n",
        "# V√©rifier s'il y a une configuration\n",
        "if hasattr(pipeline, 'model') and hasattr(pipeline.model, 'config'):\n",
        "    print(\"\\n=== Configuration du mod√®le ===\\n\")\n",
        "    config = pipeline.model.config\n",
        "    if hasattr(config, 'chronos_config'):\n",
        "        chronos_cfg = config.chronos_config\n",
        "        print(\"Configuration Chronos:\")\n",
        "        for key, value in chronos_cfg.items():\n",
        "            print(f\"  - {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 4: Pr√©visions avec num_samples (si disponible)\n",
        "# Testons diff√©rents sc√©narios pour voir quels param√®tres sont accept√©s\n",
        "\n",
        "print(\"=== Test avec diff√©rents param√®tres ===\\n\")\n",
        "\n",
        "try:\n",
        "    # Essayer avec num_samples\n",
        "    pred_samples = pipeline.predict_df(\n",
        "        simple_context_df,\n",
        "        prediction_length=10,\n",
        "        num_samples=100,  # Nombre d'√©chantillons pour pr√©visions probabilistes\n",
        "        id_column=\"id\",\n",
        "        timestamp_column=\"timestamp\",\n",
        "        target=\"target\"\n",
        "    )\n",
        "    print(\"‚úì num_samples est support√©\")\n",
        "    print(f\"  Shape des pr√©dictions: {pred_samples.shape}\")\n",
        "except TypeError as e:\n",
        "    print(f\"‚úó num_samples n'est pas support√© ou mal utilis√©\")\n",
        "    print(f\"  Erreur: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 5: Tester temperature (si disponible)\n",
        "try:\n",
        "    pred_temp = pipeline.predict_df(\n",
        "        simple_context_df,\n",
        "        prediction_length=10,\n",
        "        temperature=0.8,  # Contr√¥le la diversit√© des pr√©dictions\n",
        "        quantile_levels=[0.1, 0.5, 0.9],\n",
        "        id_column=\"id\",\n",
        "        timestamp_column=\"timestamp\",\n",
        "        target=\"target\"\n",
        "    )\n",
        "    print(\"‚úì temperature est support√©\")\n",
        "    print(f\"  Shape des pr√©dictions: {pred_temp.shape}\")\n",
        "except TypeError as e:\n",
        "    print(f\"‚úó temperature n'est pas support√© ou mal utilis√©\")\n",
        "    print(f\"  Erreur: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Utilisation de predict() avec arrays ===\\n\")\n",
        "\n",
        "# 1) S√©rie historique univari√©e\n",
        "context_tensor = torch.tensor(\n",
        "    simple_context_df['target'].values,\n",
        "    dtype=torch.float32\n",
        ")  # shape: (T,)\n",
        "\n",
        "# 2) Passage en 3D : (n_series, n_variates, history_length)\n",
        "#    Ici: (1, 1, T)\n",
        "context_3d = context_tensor.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "# 3) Pr√©dictions\n",
        "predictions = pipeline.predict(\n",
        "    inputs=context_3d,    # ou juste pipeline.predict(context_3d, prediction_length=10)\n",
        "    prediction_length=10\n",
        ")\n",
        "\n",
        "print(f\"Type des pr√©dictions: {type(predictions)}\")\n",
        "print(f\"\\nPr√©dictions:\\n{predictions}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. R√©sum√© des param√®tres d'inf√©rence\n",
        "\n",
        "Voici un r√©sum√© des param√®tres principaux pour faire de l'inf√©rence avec Chronos-2 :\n",
        "\n",
        "### Param√®tres essentiels pour `predict_df()`:\n",
        "\n",
        "1. **`context_df`**: DataFrame avec les donn√©es historiques (obligatoire)\n",
        "2. **`prediction_length`**: Nombre de pas de temps √† pr√©dire (obligatoire)\n",
        "3. **`id_column`**: Nom de la colonne identifiant les diff√©rentes s√©ries (par d√©faut: \"id\")\n",
        "4. **`timestamp_column`**: Nom de la colonne avec les timestamps (par d√©faut: \"timestamp\")\n",
        "5. **`target`**: Nom de la colonne cible √† pr√©dire (obligatoire)\n",
        "6. **`quantile_levels`**: Liste des quantiles pour pr√©visions probabilistes (ex: [0.1, 0.5, 0.9])\n",
        "7. **`future_df`**: DataFrame avec les valeurs futures des covariables (optionnel)\n",
        "8. **`num_samples`**: Nombre d'√©chantillons √† g√©n√©rer (peut varier selon la version)\n",
        "9. **`batch_size`**: Taille des lots pour le traitement (optionnel)\n",
        "\n",
        "### Param√®tres essentiels pour `predict()`:\n",
        "\n",
        "1. **`context`**: Tensor avec les donn√©es historiques\n",
        "2. **`prediction_length`**: Nombre de pas de temps √† pr√©dire\n",
        "3. **`num_samples`**: Nombre d'√©chantillons √† g√©n√©rer\n",
        "4. **`temperature`**: Temp√©rature pour l'√©chantillonnage (peut √™tre disponible)\n",
        "5. **`top_k`** / **`top_p`**: Param√®tres d'√©chantillonnage (selon la version)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Exemple complet d'inf√©rence avec tous les param√®tres\n",
        "\n",
        "Voici un exemple complet montrant comment utiliser Chronos-2 avec tous les param√®tres principaux.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple complet avec configuration personnalis√©e\n",
        "print(\"=== EXEMPLE COMPLET D'INF√âRENCE AVEC CHRONOS-2 ===\\n\")\n",
        "\n",
        "# 1. Pr√©parer les donn√©es\n",
        "context_df = simple_context_df.copy()\n",
        "print(f\"1. Donn√©es de contexte: {len(context_df)} observations\")\n",
        "print(f\"   P√©riode: {context_df['timestamp'].min()} √† {context_df['timestamp'].max()}\\n\")\n",
        "\n",
        "# 2. Configurer les param√®tres d'inf√©rence\n",
        "prediction_config = {\n",
        "    'prediction_length': 14,  # Pr√©dire 14 jours\n",
        "    'quantile_levels': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99],  # Quantiles multiples\n",
        "    'id_column': 'id',\n",
        "    'timestamp_column': 'timestamp',\n",
        "    'target': 'target'\n",
        "}\n",
        "\n",
        "print(\"2. Configuration des param√®tres:\")\n",
        "for param, value in prediction_config.items():\n",
        "    print(f\"   - {param}: {value}\")\n",
        "\n",
        "# 3. Faire les pr√©dictions\n",
        "print(\"\\n3. G√©n√©ration des pr√©dictions...\")\n",
        "predictions_df = pipeline.predict_df(\n",
        "    context_df,\n",
        "    **prediction_config\n",
        ")\n",
        "\n",
        "print(f\"   ‚úì Pr√©dictions g√©n√©r√©es: {predictions_df.shape}\")\n",
        "print(f\"   ‚úì Colonnes: {predictions_df.columns.tolist()}\\n\")\n",
        "\n",
        "# 4. Afficher un √©chantillon des r√©sultats\n",
        "print(\"4. Aper√ßu des pr√©dictions:\")\n",
        "print(predictions_df.head(10))\n",
        "\n",
        "# 5. Statistiques sur les pr√©dictions\n",
        "print(\"\\n5. Statistiques des pr√©dictions:\")\n",
        "if '0.5' in predictions_df.columns:\n",
        "    median_values = predictions_df['0.5']\n",
        "    print(f\"   - M√©diane min: {median_values.min():.4f}\")\n",
        "    print(f\"   - M√©diane max: {median_values.max():.4f}\")\n",
        "    print(f\"   - M√©diane moyenne: {median_values.mean():.4f}\")\n",
        "    \n",
        "# 6. Calculer la largeur des intervalles de confiance\n",
        "if '0.05' in predictions_df.columns and '0.95' in predictions_df.columns:\n",
        "    ic_90 = predictions_df['0.95'] - predictions_df['0.05']\n",
        "    print(f\"   - Largeur moyenne IC 90%: {ic_90.mean():.4f}\")\n",
        "    \n",
        "if '0.25' in predictions_df.columns and '0.75' in predictions_df.columns:\n",
        "    ic_50 = predictions_df['0.75'] - predictions_df['0.25']\n",
        "    print(f\"   - Largeur moyenne IC 50%: {ic_50.mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation avanc√©e des pr√©dictions avec tous les quantiles\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))\n",
        "\n",
        "# Pr√©parer les donn√©es\n",
        "pred_plot = predictions_df[predictions_df['id'] == 'series_1'].copy()\n",
        "hist_plot = context_df[context_df['id'] == 'series_1'].copy()\n",
        "\n",
        "# --- Graphique 1: Vue d'ensemble avec tous les intervalles de confiance ---\n",
        "ax1.plot(hist_plot['timestamp'], hist_plot['target'], \n",
        "         label='Donn√©es historiques', linewidth=2.5, color='#2E86AB', alpha=0.8)\n",
        "\n",
        "# M√©diane\n",
        "if '0.5' in pred_plot.columns:\n",
        "    ax1.plot(pred_plot['timestamp'], pred_plot['0.5'], \n",
        "             label='Pr√©diction (m√©diane)', linewidth=2.5, color='#A23B72', linestyle='--')\n",
        "\n",
        "# Intervalles de confiance empil√©s\n",
        "intervals = [\n",
        "    ('0.01', '0.99', 0.05, 'IC 98%'),\n",
        "    ('0.05', '0.95', 0.10, 'IC 90%'),\n",
        "    ('0.10', '0.90', 0.15, 'IC 80%'),\n",
        "    ('0.25', '0.75', 0.25, 'IC 50%'),\n",
        "]\n",
        "\n",
        "colors = ['#F18F01', '#C73E1D', '#6A994E', '#A23B72']\n",
        "for i, (q_low, q_high, alpha, label) in enumerate(intervals):\n",
        "    if q_low in pred_plot.columns and q_high in pred_plot.columns:\n",
        "        ax1.fill_between(pred_plot['timestamp'], \n",
        "                         pred_plot[q_low], \n",
        "                         pred_plot[q_high],\n",
        "                         alpha=alpha, color=colors[i % len(colors)], label=label)\n",
        "\n",
        "ax1.axvline(x=hist_plot['timestamp'].iloc[-1], color='gray', linestyle=':', \n",
        "            linewidth=2, label='D√©but des pr√©dictions')\n",
        "ax1.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Valeur', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Pr√©visions Chronos-2 avec intervalles de confiance multiples', \n",
        "              fontsize=14, fontweight='bold')\n",
        "ax1.legend(loc='best', fontsize=10)\n",
        "ax1.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "# --- Graphique 2: Zoom sur les pr√©dictions uniquement ---\n",
        "# M√©diane\n",
        "if '0.5' in pred_plot.columns:\n",
        "    ax2.plot(pred_plot['timestamp'], pred_plot['0.5'], \n",
        "             label='M√©diane (Q50)', linewidth=2.5, color='#A23B72', marker='o')\n",
        "\n",
        "# Afficher plusieurs quantiles individuellement\n",
        "quantiles_to_plot = ['0.05', '0.25', '0.75', '0.95']\n",
        "quantile_colors = ['#C73E1D', '#F18F01', '#6A994E', '#2E86AB']\n",
        "\n",
        "for q, color in zip(quantiles_to_plot, quantile_colors):\n",
        "    if q in pred_plot.columns:\n",
        "        q_label = f'Q{int(float(q)*100)}'\n",
        "        ax2.plot(pred_plot['timestamp'], pred_plot[q], \n",
        "                 label=q_label, linewidth=1.5, color=color, \n",
        "                 marker='s', markersize=4, alpha=0.7)\n",
        "\n",
        "ax2.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Valeur', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('D√©tail des quantiles de pr√©diction', fontsize=14, fontweight='bold')\n",
        "ax2.legend(loc='best', fontsize=10, ncol=2)\n",
        "ax2.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì Visualisation compl√®te des pr√©dictions avec intervalles de confiance\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 16. Bonnes pratiques pour l'inf√©rence avec Chronos-2\n",
        "\n",
        "### üéØ Choix des param√®tres\n",
        "\n",
        "**Quantiles (`quantile_levels`)**:\n",
        "- Pour des intervalles de confiance standards : `[0.1, 0.5, 0.9]` (IC 80%)\n",
        "- Pour une analyse d√©taill√©e : `[0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]`\n",
        "- Le quantile 0.5 correspond √† la m√©diane (pr√©diction centrale)\n",
        "\n",
        "**Longueur de pr√©diction (`prediction_length`)**:\n",
        "- D√©pend de la fr√©quence des donn√©es et de l'horizon souhait√©\n",
        "- G√©n√©ralement : 10-20% de la longueur du contexte est raisonnable\n",
        "- Pour des donn√©es journali√®res : 7-30 jours est courant\n",
        "\n",
        "**Nombre d'√©chantillons (`num_samples`)**:\n",
        "- Plus d'√©chantillons = pr√©dictions plus lisses mais calcul plus lent\n",
        "- Valeurs typiques : 20-100 √©chantillons\n",
        "- Pour production : 100-1000 √©chantillons selon la pr√©cision requise\n",
        "\n",
        "### ‚ö° Performance\n",
        "\n",
        "- Utilisez `batch_size` pour traiter plusieurs s√©ries en parall√®le\n",
        "- Pour GPU: augmentez `batch_size` pour maximiser l'utilisation\n",
        "- Pour CPU: r√©duisez `batch_size` si vous manquez de m√©moire\n",
        "\n",
        "### üìä Interpr√©tation des r√©sultats\n",
        "\n",
        "- Les quantiles extr√™mes (0.01, 0.99) capturent les sc√©narios rares\n",
        "- L'√©cart entre quantiles indique l'incertitude du mod√®le\n",
        "- Un IC large = haute incertitude, IC √©troit = haute confiance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 17. Utilisation avanc√©e : m√©thode `predict()` avec tensors\n",
        "\n",
        "La m√©thode `predict()` offre un contr√¥le plus bas niveau et permet de travailler directement avec des tensors PyTorch. Cette approche est utile pour :\n",
        "- Int√©grer Chronos-2 dans un pipeline ML personnalis√©\n",
        "- Avoir un contr√¥le fin sur les param√®tres d'inf√©rence\n",
        "- Traiter des donn√©es d√©j√† sous forme de tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examiner en d√©tail la m√©thode predict et ses param√®tres\n",
        "print(\"=== Documentation d√©taill√©e de la m√©thode predict() ===\\n\")\n",
        "\n",
        "# Afficher la signature\n",
        "print(\"Signature:\")\n",
        "print(inspect.signature(pipeline.predict))\n",
        "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "# Afficher la documentation\n",
        "if pipeline.predict.__doc__:\n",
        "    print(\"Documentation:\")\n",
        "    print(pipeline.predict.__doc__)\n",
        "else:\n",
        "    print(\"Pas de documentation disponible pour predict()\")\n",
        "    \n",
        "# Explorer les attributs du pipeline\n",
        "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "print(\"Type du pipeline:\", type(pipeline))\n",
        "print(\"M√©thodes disponibles:\")\n",
        "for attr in dir(pipeline):\n",
        "    if not attr.startswith('_') and callable(getattr(pipeline, attr)):\n",
        "        print(f\"  - {attr}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple d'utilisation de predict() avec des tensors\n",
        "print(\"=== Exemple avec predict() et tensors ===\\n\")\n",
        "\n",
        "# Pr√©parer les donn√©es\n",
        "context_values = simple_context_df['target'].values\n",
        "context_tensor = torch.tensor(context_values, dtype=torch.float32).unsqueeze(0)  # Shape: (1, seq_len)\n",
        "\n",
        "print(f\"1. Contexte pr√©par√©:\")\n",
        "print(f\"   - Shape: {context_tensor.shape}\")\n",
        "print(f\"   - Type: {context_tensor.dtype}\")\n",
        "print(f\"   - Device: {context_tensor.device}\\n\")\n",
        "\n",
        "# Faire des pr√©dictions avec param√®tres par d√©faut\n",
        "try:\n",
        "    predictions_basic = pipeline.predict(\n",
        "        context=context_tensor,\n",
        "        prediction_length=10\n",
        "    )\n",
        "    \n",
        "    print(f\"2. Pr√©dictions g√©n√©r√©es:\")\n",
        "    print(f\"   - Type: {type(predictions_basic)}\")\n",
        "    print(f\"   - Shape: {predictions_basic.shape}\")\n",
        "    print(f\"   - Device: {predictions_basic.device}\\n\")\n",
        "    \n",
        "    print(f\"3. Aper√ßu des pr√©dictions:\")\n",
        "    print(predictions_basic)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors de l'inf√©rence: {e}\")\n",
        "    print(f\"Type d'erreur: {type(e).__name__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Essayer avec num_samples pour obtenir plusieurs trajectoires\n",
        "print(\"\\n=== Test avec num_samples ===\\n\")\n",
        "\n",
        "try:\n",
        "    predictions_samples = pipeline.predict(\n",
        "        context=context_tensor,\n",
        "        prediction_length=10,\n",
        "        num_samples=20  # G√©n√©rer 20 trajectoires de pr√©diction\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úì Pr√©dictions avec √©chantillons multiples:\")\n",
        "    print(f\"   - Shape: {predictions_samples.shape}\")\n",
        "    print(f\"   - Expected shape: (num_samples, batch_size, prediction_length)\")\n",
        "    \n",
        "    # Calculer statistiques\n",
        "    print(f\"\\n   Statistiques par pas de temps:\")\n",
        "    mean_pred = predictions_samples.mean(dim=0).squeeze()\n",
        "    std_pred = predictions_samples.std(dim=0).squeeze()\n",
        "    \n",
        "    for i in range(min(5, len(mean_pred))):\n",
        "        print(f\"   - t+{i+1}: {mean_pred[i]:.4f} ¬± {std_pred[i]:.4f}\")\n",
        "        \n",
        "except TypeError as e:\n",
        "    print(f\"‚úó num_samples non support√© dans cette signature\")\n",
        "    print(f\"   Erreur: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚úó Erreur: {type(e).__name__}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tester d'autres param√®tres potentiels\n",
        "print(\"\\n=== Test de param√®tres additionnels ===\\n\")\n",
        "\n",
        "# Liste de param√®tres √† tester\n",
        "params_to_test = [\n",
        "    ('temperature', 0.8, \"Contr√¥le la diversit√© des pr√©dictions\"),\n",
        "    ('top_k', 50, \"Limite aux k tokens les plus probables\"),\n",
        "    ('top_p', 0.9, \"√âchantillonnage nucleus\"),\n",
        "    ('batch_size', 1, \"Taille du batch\"),\n",
        "]\n",
        "\n",
        "for param_name, param_value, description in params_to_test:\n",
        "    try:\n",
        "        kwargs = {\n",
        "            'context': context_tensor,\n",
        "            'prediction_length': 10,\n",
        "            param_name: param_value\n",
        "        }\n",
        "        \n",
        "        pred_test = pipeline.predict(**kwargs)\n",
        "        print(f\"‚úì {param_name:20s}: Support√© - {description}\")\n",
        "        print(f\"  Shape: {pred_test.shape}\")\n",
        "        \n",
        "    except TypeError as e:\n",
        "        if \"unexpected keyword argument\" in str(e):\n",
        "            print(f\"‚úó {param_name:20s}: Non support√© dans cette version\")\n",
        "        else:\n",
        "            print(f\"‚úó {param_name:20s}: Erreur - {str(e)[:60]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚úó {param_name:20s}: Erreur - {type(e).__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 18. Code template r√©utilisable pour l'inf√©rence\n",
        "\n",
        "Voici un template complet que vous pouvez r√©utiliser pour faire de l'inf√©rence avec Chronos-2 :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "TEMPLATE R√âUTILISABLE POUR L'INF√âRENCE AVEC CHRONOS-2\n",
        "========================================================\n",
        "\n",
        "Ce template peut √™tre copi√© et adapt√© pour vos propres donn√©es.\n",
        "\"\"\"\n",
        "\n",
        "def make_chronos2_predictions(\n",
        "    context_df,\n",
        "    prediction_length=30,\n",
        "    quantile_levels=None,\n",
        "    id_column=\"id\",\n",
        "    timestamp_column=\"timestamp\",\n",
        "    target_column=\"target\",\n",
        "    future_df=None,\n",
        "    pipeline=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Fait des pr√©dictions avec Chronos-2 sur un DataFrame pandas.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    context_df : pd.DataFrame\n",
        "        DataFrame avec les donn√©es historiques\n",
        "    prediction_length : int\n",
        "        Nombre de pas de temps √† pr√©dire\n",
        "    quantile_levels : list, optional\n",
        "        Liste des quantiles √† calculer (default: [0.1, 0.5, 0.9])\n",
        "    id_column : str\n",
        "        Nom de la colonne identifiant les s√©ries\n",
        "    timestamp_column : str\n",
        "        Nom de la colonne avec les timestamps\n",
        "    target_column : str\n",
        "        Nom de la colonne cible\n",
        "    future_df : pd.DataFrame, optional\n",
        "        DataFrame avec les valeurs futures des covariables\n",
        "    pipeline : Chronos2Pipeline\n",
        "        Instance du pipeline Chronos-2 (sera cr√©√©e si None)\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        DataFrame avec les pr√©dictions pour chaque quantile\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    from chronos import Chronos2Pipeline\n",
        "    \n",
        "    # Param√®tres par d√©faut\n",
        "    if quantile_levels is None:\n",
        "        quantile_levels = [0.1, 0.5, 0.9]\n",
        "    \n",
        "    # Charger le pipeline si n√©cessaire\n",
        "    if pipeline is None:\n",
        "        print(\"Chargement du pipeline Chronos-2...\")\n",
        "        pipeline = Chronos2Pipeline.from_pretrained(\n",
        "            \"amazon/chronos-2\",\n",
        "            device_map=\"mps\"  # ou \"cuda\" pour GPU NVIDIA, \"cpu\" pour CPU\n",
        "        )\n",
        "    \n",
        "    # Configuration de la pr√©diction\n",
        "    config = {\n",
        "        'prediction_length': prediction_length,\n",
        "        'quantile_levels': quantile_levels,\n",
        "        'id_column': id_column,\n",
        "        'timestamp_column': timestamp_column,\n",
        "        'target': target_column\n",
        "    }\n",
        "    \n",
        "    # Ajouter les covariables si disponibles\n",
        "    if future_df is not None:\n",
        "        config['future_df'] = future_df\n",
        "    \n",
        "    # Faire les pr√©dictions\n",
        "    print(f\"G√©n√©ration de {prediction_length} pr√©dictions...\")\n",
        "    predictions_df = pipeline.predict_df(context_df, **config)\n",
        "    \n",
        "    print(f\"‚úì Pr√©dictions g√©n√©r√©es: {predictions_df.shape}\")\n",
        "    \n",
        "    return predictions_df\n",
        "\n",
        "# Exemple d'utilisation du template\n",
        "print(\"=== EXEMPLE D'UTILISATION DU TEMPLATE ===\\n\")\n",
        "\n",
        "predictions = make_chronos2_predictions(\n",
        "    context_df=simple_context_df,\n",
        "    prediction_length=14,\n",
        "    quantile_levels=[0.05, 0.25, 0.5, 0.75, 0.95],\n",
        "    id_column=\"id\",\n",
        "    timestamp_column=\"timestamp\",\n",
        "    target_column=\"target\",\n",
        "    pipeline=pipeline  # R√©utiliser le pipeline d√©j√† charg√©\n",
        ")\n",
        "\n",
        "print(\"\\nR√©sultat:\")\n",
        "print(predictions.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 19. Ressources utiles\n",
        "\n",
        "### Documentation officielle\n",
        "\n",
        "- **Page du mod√®le**: https://huggingface.co/amazon/chronos-2\n",
        "- **GitHub Repository**: https://github.com/amazon-science/chronos-forecasting\n",
        "- **Paper Chronos-2**: https://arxiv.org/abs/2510.15821\n",
        "\n",
        "### Param√®tres d'inf√©rence principaux\n",
        "\n",
        "| Param√®tre | Description | Valeurs typiques |\n",
        "|-----------|-------------|------------------|\n",
        "| `prediction_length` | Horizon de pr√©vision | 7-30 pour donn√©es journali√®res |\n",
        "| `quantile_levels` | Quantiles pour IC | [0.1, 0.5, 0.9] ou [0.05, 0.25, 0.5, 0.75, 0.95] |\n",
        "| `num_samples` | Nombre d'√©chantillons | 20-100 (dev), 100-1000 (prod) |\n",
        "| `batch_size` | Taille des lots | Selon m√©moire disponible |\n",
        "| `temperature` | Diversit√© des pr√©dictions | 0.7-1.0 (si disponible) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ R√©sum√©\n",
        "\n",
        "Ce notebook vous a montr√© comment :\n",
        "\n",
        "1. ‚úì Charger et explorer le mod√®le Chronos-2\n",
        "2. ‚úì Utiliser la m√©thode `predict_df()` pour faire des pr√©dictions sur des DataFrames\n",
        "3. ‚úì Sp√©cifier les param√®tres d'inf√©rence (quantiles, prediction_length, etc.)\n",
        "4. ‚úì Utiliser la m√©thode `predict()` pour un contr√¥le bas niveau avec des tensors\n",
        "5. ‚úì Visualiser les pr√©dictions avec des intervalles de confiance\n",
        "6. ‚úì Cr√©er un template r√©utilisable pour vos propres projets\n",
        "\n",
        "**Param√®tres d'inf√©rence principaux :**\n",
        "- `prediction_length`: Horizon de pr√©vision\n",
        "- `quantile_levels`: Quantiles pour pr√©visions probabilistes\n",
        "- `num_samples`: Nombre d'√©chantillons √† g√©n√©rer\n",
        "- `id_column`, `timestamp_column`, `target`: Colonnes du DataFrame\n",
        "- `future_df`: Covariables futures (optionnel)\n",
        "\n",
        "Vous √™tes maintenant pr√™t √† utiliser Chronos-2 pour vos propres pr√©visions de s√©ries temporelles ! üöÄ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 20. Utilisation avec votre propre dataset\n",
        "\n",
        "Cette section montre comment utiliser Chronos-2 avec votre dataset personnalis√©.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pr√©paration de votre dataset pour Chronos-2\n",
        "# \n",
        "# Votre dataset doit avoir:\n",
        "# - Une colonne 'date' (ou similaire) avec les timestamps\n",
        "# - Des colonnes num√©riques pour les s√©ries temporelles √† pr√©dire\n",
        "# - Optionnellement: d'autres colonnes comme covariables\n",
        "\n",
        "print(\"=== PR√âPARATION DU DATASET ===\\n\")\n",
        "\n",
        "# Supposons que vous avez votre DataFrame dans une variable 'df'\n",
        "# Si ce n'est pas le cas, chargez-le ici:\n",
        "# df = pd.read_csv('votre_fichier.csv')\n",
        "# ou\n",
        "# df = pd.read_excel('votre_fichier.xlsx')\n",
        "\n",
        "# Afficher les informations du dataset\n",
        "print(\"Structure du dataset:\")\n",
        "print(f\"  - Nombre de lignes: {len(df)}\")\n",
        "print(f\"  - Nombre de colonnes: {len(df.columns)}\")\n",
        "print(f\"  - Colonnes: {df.columns.tolist()}\\n\")\n",
        "\n",
        "# Afficher les premi√®res lignes\n",
        "print(\"Premi√®res lignes:\")\n",
        "print(df.head())\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# V√©rifier les types de donn√©es\n",
        "print(\"Types de donn√©es:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# V√©rifier les valeurs manquantes\n",
        "print(\"Valeurs manquantes par colonne:\")\n",
        "missing = df.isnull().sum()\n",
        "print(missing[missing > 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonction pour pr√©parer le dataset au format Chronos-2\n",
        "def prepare_data_for_chronos2(\n",
        "    df,\n",
        "    date_column='date',\n",
        "    target_columns=None,\n",
        "    covariate_columns=None,\n",
        "    id_value='series_1',\n",
        "    freq=None,\n",
        "    fill_method='forward'\n",
        "):\n",
        "    \"\"\"\n",
        "    Pr√©pare un DataFrame pour l'inf√©rence avec Chronos-2.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame avec les donn√©es brutes\n",
        "    date_column : str\n",
        "        Nom de la colonne contenant les dates\n",
        "    target_columns : list or str\n",
        "        Colonne(s) √† pr√©dire. Si None, utilise toutes les colonnes num√©riques sauf date\n",
        "    covariate_columns : list\n",
        "        Colonnes √† utiliser comme covariables (optionnel)\n",
        "    id_value : str\n",
        "        Identifiant de la s√©rie temporelle\n",
        "    freq : str or None\n",
        "        Fr√©quence des donn√©es (ex: 'D' pour quotidien, 'M' pour mensuel)\n",
        "        Si None, sera inf√©r√©e automatiquement\n",
        "    fill_method : str\n",
        "        M√©thode pour remplir les valeurs manquantes lors de la cr√©ation d'une s√©rie r√©guli√®re\n",
        "        'forward': forward fill, 'backward': backward fill, 'interpolate': interpolation lin√©aire\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        DataFrame format√© pour Chronos-2 avec colonnes: id, timestamp, target, [covariates]\n",
        "    \"\"\"\n",
        "    # Copier le DataFrame\n",
        "    df_prep = df.copy()\n",
        "    \n",
        "    # Convertir la colonne de date en timestamp\n",
        "    if date_column in df_prep.columns:\n",
        "        df_prep['timestamp'] = pd.to_datetime(df_prep[date_column])\n",
        "    else:\n",
        "        raise ValueError(f\"Colonne '{date_column}' introuvable dans le DataFrame\")\n",
        "    \n",
        "    # Trier par timestamp et supprimer les doublons\n",
        "    df_prep = df_prep.sort_values('timestamp').drop_duplicates(subset=['timestamp']).reset_index(drop=True)\n",
        "    \n",
        "    # Identifier les colonnes num√©riques (sauf date et timestamp)\n",
        "    numeric_cols = df_prep.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if 'timestamp' in numeric_cols:\n",
        "        numeric_cols.remove('timestamp')\n",
        "    \n",
        "    # D√©terminer les colonnes cibles\n",
        "    if target_columns is None:\n",
        "        # Par d√©faut, utiliser toutes les colonnes num√©riques\n",
        "        target_columns = numeric_cols\n",
        "    elif isinstance(target_columns, str):\n",
        "        target_columns = [target_columns]\n",
        "    \n",
        "    # V√©rifier que les colonnes cibles existent\n",
        "    for col in target_columns:\n",
        "        if col not in df_prep.columns:\n",
        "            raise ValueError(f\"Colonne cible '{col}' introuvable\")\n",
        "    \n",
        "    # D√©terminer les covariables (toutes les autres colonnes num√©riques)\n",
        "    if covariate_columns is None:\n",
        "        covariate_columns = [col for col in numeric_cols if col not in target_columns]\n",
        "    \n",
        "    # Inf√©rer ou d√©terminer la fr√©quence\n",
        "    if freq is None:\n",
        "        # Essayer d'inf√©rer la fr√©quence √† partir des timestamps\n",
        "        timestamps_sorted = df_prep['timestamp'].sort_values().reset_index(drop=True)\n",
        "        freq = pd.infer_freq(timestamps_sorted)\n",
        "        \n",
        "        if freq is None:\n",
        "            # Si l'inf√©rence √©choue, calculer la fr√©quence la plus commune\n",
        "            if len(timestamps_sorted) > 1:\n",
        "                diffs = timestamps_sorted.diff().dropna()\n",
        "                most_common_diff = diffs.mode()\n",
        "                if len(most_common_diff) > 0:\n",
        "                    # Convertir la diff√©rence la plus commune en fr√©quence\n",
        "                    diff_value = most_common_diff.iloc[0]\n",
        "                    if pd.Timedelta(days=1) <= diff_value <= pd.Timedelta(days=1.5):\n",
        "                        freq = 'D'  # Daily\n",
        "                    elif pd.Timedelta(days=7) <= diff_value <= pd.Timedelta(days=8):\n",
        "                        freq = 'W'  # Weekly\n",
        "                    elif pd.Timedelta(days=28) <= diff_value <= pd.Timedelta(days=32):\n",
        "                        freq = 'M'  # Monthly\n",
        "                    elif pd.Timedelta(days=90) <= diff_value <= pd.Timedelta(days=95):\n",
        "                        freq = 'Q'  # Quarterly\n",
        "                    else:\n",
        "                        # Utiliser la diff√©rence moyenne comme fr√©quence personnalis√©e\n",
        "                        freq = diff_value\n",
        "                        print(f\"‚ö†Ô∏è  Utilisation d'une fr√©quence personnalis√©e: {freq}\")\n",
        "                else:\n",
        "                    raise ValueError(\"Impossible de d√©terminer la fr√©quence des donn√©es. Veuillez sp√©cifier 'freq' manuellement.\")\n",
        "            else:\n",
        "                raise ValueError(\"Pas assez de donn√©es pour inf√©rer la fr√©quence. Veuillez sp√©cifier 'freq' manuellement.\")\n",
        "    \n",
        "    print(f\"‚úì Fr√©quence utilis√©e: {freq}\")\n",
        "    \n",
        "    # Cr√©er une s√©rie de timestamps r√©guli√®re\n",
        "    min_timestamp = df_prep['timestamp'].min()\n",
        "    max_timestamp = df_prep['timestamp'].max()\n",
        "    \n",
        "    # Cr√©er un index de dates r√©guli√®res\n",
        "    if isinstance(freq, str):\n",
        "        regular_index = pd.date_range(start=min_timestamp, end=max_timestamp, freq=freq)\n",
        "    else:\n",
        "        # Si freq est un Timedelta, cr√©er manuellement\n",
        "        regular_index = pd.date_range(start=min_timestamp, end=max_timestamp, freq=freq)\n",
        "    \n",
        "    print(f\"‚úì S√©rie r√©guli√®re cr√©√©e: {len(regular_index)} timestamps de {min_timestamp} √† {max_timestamp}\")\n",
        "    \n",
        "    # Cr√©er le DataFrame au format long pour Chronos-2\n",
        "    result_dfs = []\n",
        "    \n",
        "    for target_col in target_columns:\n",
        "        # Cr√©er un DataFrame pour cette s√©rie avec les timestamps r√©guliers\n",
        "        series_df = pd.DataFrame({\n",
        "            'id': [id_value] * len(regular_index),\n",
        "            'timestamp': regular_index\n",
        "        })\n",
        "        \n",
        "        # R√©indexer les donn√©es originales sur les timestamps r√©guliers\n",
        "        target_series = df_prep.set_index('timestamp')[target_col]\n",
        "        target_series = target_series.reindex(regular_index)\n",
        "        \n",
        "        # Remplir les valeurs manquantes\n",
        "        if fill_method == 'forward':\n",
        "            target_series = target_series.ffill()\n",
        "        elif fill_method == 'backward':\n",
        "            target_series = target_series.bfill()\n",
        "        elif fill_method == 'interpolate':\n",
        "            target_series = target_series.interpolate(method='linear')\n",
        "        else:\n",
        "            # Par d√©faut, forward fill puis backward fill\n",
        "            target_series = target_series.ffill().bfill()\n",
        "        \n",
        "        series_df['target'] = target_series.values\n",
        "        \n",
        "        # Ajouter les covariables si sp√©cifi√©es\n",
        "        for cov_col in covariate_columns:\n",
        "            if cov_col in df_prep.columns:\n",
        "                cov_series = df_prep.set_index('timestamp')[cov_col]\n",
        "                cov_series = cov_series.reindex(regular_index)\n",
        "                \n",
        "                # Remplir les valeurs manquantes de la m√™me mani√®re\n",
        "                if fill_method == 'forward':\n",
        "                    cov_series = cov_series.ffill()\n",
        "                elif fill_method == 'backward':\n",
        "                    cov_series = cov_series.bfill()\n",
        "                elif fill_method == 'interpolate':\n",
        "                    cov_series = cov_series.interpolate(method='linear')\n",
        "                else:\n",
        "                    cov_series = cov_series.ffill().bfill()\n",
        "                \n",
        "                series_df[cov_col] = cov_series.values\n",
        "        \n",
        "        # Supprimer les lignes o√π target est toujours NaN (au d√©but si n√©cessaire)\n",
        "        series_df = series_df.dropna(subset=['target']).reset_index(drop=True)\n",
        "        \n",
        "        result_dfs.append(series_df)\n",
        "    \n",
        "    # Si une seule colonne cible, retourner directement\n",
        "    if len(result_dfs) == 1:\n",
        "        result_df = result_dfs[0]\n",
        "    else:\n",
        "        # Sinon, concat√©ner avec un id diff√©rent pour chaque s√©rie\n",
        "        for i, df_series in enumerate(result_dfs):\n",
        "            df_series['id'] = f\"{id_value}_{target_columns[i]}\"\n",
        "        result_df = pd.concat(result_dfs, ignore_index=True)\n",
        "    \n",
        "    # V√©rifier que la fr√©quence est bien r√©guli√®re\n",
        "    if len(result_df) > 1:\n",
        "        inferred_freq = pd.infer_freq(result_df['timestamp'].unique())\n",
        "        if inferred_freq is None:\n",
        "            print(\"‚ö†Ô∏è  Attention: La s√©rie finale n'a pas une fr√©quence r√©guli√®re d√©tectable\")\n",
        "        else:\n",
        "            print(f\"‚úì Fr√©quence finale v√©rifi√©e: {inferred_freq}\")\n",
        "    \n",
        "    return result_df, target_columns, covariate_columns\n",
        "\n",
        "print(\"‚úì Fonction de pr√©paration cr√©√©e\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 1: Pr√©parer le dataset pour une seule colonne cible\n",
        "# Remplacez 'gdp' par la colonne que vous souhaitez pr√©dire\n",
        "\n",
        "print(\"=== EXEMPLE 1: PR√âDICTION UNIVARI√âE ===\\n\")\n",
        "\n",
        "# Choisir une colonne cible (exemple: 'gdp')\n",
        "# Vous pouvez changer cette valeur selon vos besoins\n",
        "target_column = 'gdp'  # Changez selon votre besoin\n",
        "\n",
        "# Pr√©parer les donn√©es\n",
        "try:\n",
        "    context_df, targets, covariates = prepare_data_for_chronos2(\n",
        "        df=df,\n",
        "        date_column='date',\n",
        "        target_columns=target_column,  # Pr√©dire une seule colonne\n",
        "        id_value='ecb_data',\n",
        "        freq=None  # Sera inf√©r√© automatiquement\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úì Dataset pr√©par√©:\")\n",
        "    print(f\"  - Colonne cible: {target_column}\")\n",
        "    print(f\"  - Covariables: {covariates[:5] if len(covariates) > 5 else covariates}...\")\n",
        "    print(f\"  - Nombre de lignes: {len(context_df)}\")\n",
        "    print(f\"  - P√©riode: {context_df['timestamp'].min()} √† {context_df['timestamp'].max()}\\n\")\n",
        "    \n",
        "    # Afficher un aper√ßu\n",
        "    print(\"Aper√ßu des donn√©es pr√©par√©es:\")\n",
        "    print(context_df.head(10))\n",
        "    print(f\"\\nColonnes: {context_df.columns.tolist()}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erreur lors de la pr√©paration: {e}\")\n",
        "    print(f\"   Type: {type(e).__name__}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Inspection des donn√©es d'entr√©e du mod√®le\n",
        "\n",
        "Avant de faire les pr√©dictions, examinons exactement ce qui est donn√© au mod√®le Chronos-2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspecter les donn√©es qui seront pass√©es au mod√®le\n",
        "print(\"=== DONN√âES D'ENTR√âE DU MOD√àLE CHRONOS-2 ===\\n\")\n",
        "\n",
        "if 'context_df' in globals():\n",
        "    print(\"üìã Structure du DataFrame 'context_df' (donn√©es historiques):\")\n",
        "    print(f\"  - Nombre de lignes: {len(context_df)}\")\n",
        "    print(f\"  - Nombre de colonnes: {len(context_df.columns)}\")\n",
        "    print(f\"  - Colonnes: {context_df.columns.tolist()}\\n\")\n",
        "    \n",
        "    print(\"üìÖ Informations temporelles:\")\n",
        "    print(f\"  - Premi√®re date: {context_df['timestamp'].min()}\")\n",
        "    print(f\"  - Derni√®re date: {context_df['timestamp'].max()}\")\n",
        "    print(f\"  - P√©riode couverte: {(context_df['timestamp'].max() - context_df['timestamp'].min()).days} jours\")\n",
        "    \n",
        "    # V√©rifier la fr√©quence\n",
        "    freq = pd.infer_freq(context_df['timestamp'].sort_values())\n",
        "    if freq:\n",
        "        print(f\"  - Fr√©quence d√©tect√©e: {freq}\")\n",
        "    else:\n",
        "        print(f\"  - ‚ö†Ô∏è  Fr√©quence non d√©tect√©e automatiquement\")\n",
        "    print()\n",
        "    \n",
        "    print(\"üéØ Colonne cible (target):\")\n",
        "    target_col = 'target'\n",
        "    if target_col in context_df.columns:\n",
        "        print(f\"  - Nom: '{target_col}'\")\n",
        "        print(f\"  - Type: {context_df[target_col].dtype}\")\n",
        "        print(f\"  - Valeurs non-nulles: {context_df[target_col].notna().sum()} / {len(context_df)}\")\n",
        "        print(f\"  - Valeurs manquantes: {context_df[target_col].isna().sum()}\")\n",
        "        print(f\"  - Min: {context_df[target_col].min():.4f}\")\n",
        "        print(f\"  - Max: {context_df[target_col].max():.4f}\")\n",
        "        print(f\"  - Moyenne: {context_df[target_col].mean():.4f}\")\n",
        "    print()\n",
        "    \n",
        "    print(\"üìä Aper√ßu des donn√©es (premi√®res 10 lignes):\")\n",
        "    print(context_df.head(10))\n",
        "    print()\n",
        "    \n",
        "    print(\"üìä Aper√ßu des donn√©es (derni√®res 10 lignes):\")\n",
        "    print(context_df.tail(10))\n",
        "    print()\n",
        "    \n",
        "    # Identifier les covariables (colonnes autres que id, timestamp, target)\n",
        "    covariate_cols = [col for col in context_df.columns \n",
        "                     if col not in ['id', 'timestamp', 'target']]\n",
        "    \n",
        "    if covariate_cols:\n",
        "        print(f\"üìà Covariables d√©tect√©es ({len(covariate_cols)}):\")\n",
        "        for col in covariate_cols:\n",
        "            non_null = context_df[col].notna().sum()\n",
        "            print(f\"  - '{col}': {non_null}/{len(context_df)} valeurs non-nulles\")\n",
        "        print()\n",
        "    else:\n",
        "        print(\"üìà Covariables: Aucune (pr√©diction univari√©e pure)\\n\")\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nüí° R√âSUM√â: Ce qui est donn√© au mod√®le Chronos-2:\")\n",
        "    print(f\"  1. ‚úÖ {len(context_df)} observations historiques\")\n",
        "    print(f\"  2. ‚úÖ Colonne 'id': identifie la s√©rie temporelle\")\n",
        "    print(f\"  3. ‚úÖ Colonne 'timestamp': dates r√©guli√®res\")\n",
        "    print(f\"  4. ‚úÖ Colonne 'target': valeurs historiques √† pr√©dire\")\n",
        "    if covariate_cols:\n",
        "        print(f\"  5. ‚úÖ {len(covariate_cols)} covariables: {', '.join(covariate_cols[:3])}{'...' if len(covariate_cols) > 3 else ''}\")\n",
        "    \n",
        "    # Calculer la longueur de pr√©diction\n",
        "    pred_len = min(1024, max(12, len(context_df) // 10))\n",
        "    print(f\"\\n   Le mod√®le va utiliser ces donn√©es historiques pour pr√©dire\")\n",
        "    print(f\"   les {pred_len} prochaines valeurs.\\n\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Le DataFrame 'context_df' n'existe pas encore.\")\n",
        "    print(\"   Ex√©cutez d'abord la cellule 'Exemple 1' pour pr√©parer les donn√©es.\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiser les donn√©es d'entr√©e du mod√®le\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"=== VISUALISATION DES DONN√âES D'ENTR√âE ===\\n\")\n",
        "\n",
        "if 'context_df' in globals():\n",
        "    try:\n",
        "        fig, ax = plt.subplots(figsize=(14, 6))\n",
        "        \n",
        "        # Tracer la s√©rie temporelle historique\n",
        "        ax.plot(context_df['timestamp'], context_df['target'], \n",
        "                linewidth=2, color='#2E86AB', marker='o', markersize=3, \n",
        "                label='Donn√©es historiques (entr√©e du mod√®le)')\n",
        "        \n",
        "        # Marquer le dernier point (point de d√©part pour les pr√©dictions)\n",
        "        last_idx = len(context_df) - 1\n",
        "        ax.plot(context_df['timestamp'].iloc[last_idx], context_df['target'].iloc[last_idx],\n",
        "                marker='*', markersize=15, color='red', \n",
        "                label='Dernier point (d√©but des pr√©dictions)')\n",
        "        \n",
        "        ax.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel('Valeur (target)', fontsize=12, fontweight='bold')\n",
        "        ax.set_title('Donn√©es historiques fournies au mod√®le Chronos-2', \n",
        "                     fontsize=14, fontweight='bold')\n",
        "        ax.legend(loc='best', fontsize=10)\n",
        "        ax.grid(True, alpha=0.3, linestyle='--')\n",
        "        \n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"‚úì Graphique des donn√©es d'entr√©e cr√©√©\")\n",
        "        print(f\"\\nüìä Statistiques de la s√©rie:\")\n",
        "        print(f\"   - Nombre de points: {len(context_df)}\")\n",
        "        print(f\"   - P√©riode: {context_df['timestamp'].min().strftime('%Y-%m-%d')} √† {context_df['timestamp'].max().strftime('%Y-%m-%d')}\")\n",
        "        print(f\"   - Valeur min: {context_df['target'].min():.4f}\")\n",
        "        print(f\"   - Valeur max: {context_df['target'].max():.4f}\")\n",
        "        print(f\"   - Valeur moyenne: {context_df['target'].mean():.4f}\")\n",
        "        print(f\"   - √âcart-type: {context_df['target'].std():.4f}\\n\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur lors de la visualisation: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Le DataFrame 'context_df' n'existe pas encore.\")\n",
        "    print(\"   Ex√©cutez d'abord la cellule 'Exemple 1' pour pr√©parer les donn√©es.\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 2: Faire des pr√©dictions avec votre dataset\n",
        "print(\"=== EXEMPLE 2: INF√âRENCE AVEC VOTRE DATASET ===\\n\")\n",
        "\n",
        "# S'assurer que le pipeline est charg√©\n",
        "if 'pipeline' not in globals():\n",
        "    print(\"Chargement du pipeline Chronos-2...\")\n",
        "    from chronos import Chronos2Pipeline\n",
        "    pipeline = Chronos2Pipeline.from_pretrained(\n",
        "        \"amazon/chronos-2\",\n",
        "        device_map=\"mps\"  # ou \"cuda\" pour GPU NVIDIA, \"cpu\" pour CPU\n",
        "    )\n",
        "    print(\"‚úì Pipeline charg√©\\n\")\n",
        "\n",
        "# Faire des pr√©dictions\n",
        "try:\n",
        "    # D√©terminer la longueur de pr√©diction (par exemple, 10% de la longueur du contexte)\n",
        "    # Limiter √† 1024 car Chronos-2 recommande prediction_length <= 1024\n",
        "    prediction_length = min(1024, max(12, len(context_df) // 10))\n",
        "    print(f\"Longueur de pr√©diction: {prediction_length} pas de temps\")\n",
        "    if len(context_df) // 10 > 1024:\n",
        "        print(f\"‚ö†Ô∏è  Note: La longueur calcul√©e ({len(context_df) // 10}) a √©t√© limit√©e √† 1024 (recommandation Chronos-2)\\n\")\n",
        "    else:\n",
        "        print()\n",
        "    \n",
        "    predictions = pipeline.predict_df(\n",
        "        context_df,\n",
        "        prediction_length=prediction_length,\n",
        "        quantile_levels=[0.05, 0.25, 0.5, 0.75, 0.95],  # Quantiles pour intervalles de confiance\n",
        "        id_column=\"id\",\n",
        "        timestamp_column=\"timestamp\",\n",
        "        target=\"target\"\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úì Pr√©dictions g√©n√©r√©es avec succ√®s!\")\n",
        "    print(f\"  - Shape: {predictions.shape}\")\n",
        "    print(f\"  - Colonnes: {predictions.columns.tolist()}\\n\")\n",
        "    \n",
        "    print(\"Aper√ßu des pr√©dictions:\")\n",
        "    print(predictions.head(10))\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erreur lors de l'inf√©rence: {e}\")\n",
        "    print(f\"   Type: {type(e).__name__}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiser les pr√©dictions avec les donn√©es historiques\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"=== VISUALISATION DES PR√âDICTIONS ===\\n\")\n",
        "\n",
        "try:\n",
        "    fig, ax = plt.subplots(figsize=(16, 8))\n",
        "    \n",
        "    # Filtrer les donn√©es pour la s√©rie sp√©cifique\n",
        "    series_id = context_df['id'].iloc[0]\n",
        "    hist_data = context_df[context_df['id'] == series_id].copy()\n",
        "    pred_data = predictions[predictions['id'] == series_id].copy()\n",
        "    \n",
        "    # Afficher les donn√©es historiques\n",
        "    ax.plot(hist_data['timestamp'], hist_data['target'], \n",
        "            label='Donn√©es historiques', linewidth=2.5, color='#2E86AB', marker='o', markersize=3)\n",
        "    \n",
        "    # Afficher la m√©diane (quantile 0.5)\n",
        "    if '0.5' in pred_data.columns:\n",
        "        ax.plot(pred_data['timestamp'], pred_data['0.5'], \n",
        "                label='Pr√©diction (m√©diane)', linewidth=2.5, color='#A23B72', \n",
        "                linestyle='--', marker='s', markersize=4)\n",
        "    \n",
        "    # Afficher les intervalles de confiance\n",
        "    if '0.05' in pred_data.columns and '0.95' in pred_data.columns:\n",
        "        ax.fill_between(pred_data['timestamp'], \n",
        "                         pred_data['0.05'], \n",
        "                         pred_data['0.95'],\n",
        "                         alpha=0.2, color='red', label='IC 90%')\n",
        "    \n",
        "    if '0.25' in pred_data.columns and '0.75' in pred_data.columns:\n",
        "        ax.fill_between(pred_data['timestamp'], \n",
        "                         pred_data['0.25'], \n",
        "                         pred_data['0.75'],\n",
        "                         alpha=0.3, color='red', label='IC 50%')\n",
        "    \n",
        "    # Ligne verticale pour s√©parer historique et pr√©dictions\n",
        "    if len(hist_data) > 0:\n",
        "        ax.axvline(x=hist_data['timestamp'].iloc[-1], color='gray', \n",
        "                   linestyle=':', linewidth=2, label='D√©but des pr√©dictions')\n",
        "    \n",
        "    ax.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel(f'Valeur ({target_column})', fontsize=12, fontweight='bold')\n",
        "    ax.set_title(f'Pr√©visions Chronos-2 pour {target_column}', fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='best', fontsize=10)\n",
        "    ax.grid(True, alpha=0.3, linestyle='--')\n",
        "    \n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úì Visualisation cr√©√©e\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erreur lors de la visualisation: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 3: Pr√©dire plusieurs colonnes simultan√©ment (multivari√©)\n",
        "print(\"=== EXEMPLE 3: PR√âDICTION MULTIVARI√âE ===\\n\")\n",
        "\n",
        "# Choisir plusieurs colonnes √† pr√©dire\n",
        "# Exemple: pr√©dire gdp, investment, et production_kg simultan√©ment\n",
        "target_columns_multivariate = ['gdp', 'investment', 'production_kg']  # Changez selon vos besoins\n",
        "\n",
        "# Filtrer pour ne garder que les colonnes qui existent\n",
        "target_columns_multivariate = [col for col in target_columns_multivariate if col in df.columns]\n",
        "\n",
        "if len(target_columns_multivariate) > 0:\n",
        "    print(f\"Colonnes s√©lectionn√©es pour pr√©diction multivari√©e: {target_columns_multivariate}\\n\")\n",
        "    \n",
        "    try:\n",
        "        # Pr√©parer les donn√©es pour chaque colonne\n",
        "        all_context_dfs = []\n",
        "        \n",
        "        for target_col in target_columns_multivariate:\n",
        "            context_df_multi, _, _ = prepare_data_for_chronos2(\n",
        "                df=df,\n",
        "                date_column='date',\n",
        "                target_columns=target_col,\n",
        "                id_value=f'ecb_{target_col}',\n",
        "                freq=None\n",
        "            )\n",
        "            all_context_dfs.append(context_df_multi)\n",
        "        \n",
        "        # Concat√©ner tous les DataFrames\n",
        "        context_df_multi = pd.concat(all_context_dfs, ignore_index=True)\n",
        "        \n",
        "        print(f\"‚úì Dataset multivari√© pr√©par√©:\")\n",
        "        print(f\"  - Nombre de s√©ries: {len(target_columns_multivariate)}\")\n",
        "        print(f\"  - Nombre total de lignes: {len(context_df_multi)}\")\n",
        "        print(f\"  - IDs uniques: {context_df_multi['id'].unique().tolist()}\\n\")\n",
        "        \n",
        "        # Faire des pr√©dictions pour toutes les s√©ries\n",
        "        # Limiter √† 1024 car Chronos-2 recommande prediction_length <= 1024\n",
        "        prediction_length_multi = min(1024, max(12, len(context_df_multi) // (10 * len(target_columns_multivariate))))\n",
        "        \n",
        "        predictions_multi = pipeline.predict_df(\n",
        "            context_df_multi,\n",
        "            prediction_length=prediction_length_multi,\n",
        "            quantile_levels=[0.1, 0.5, 0.9],\n",
        "            id_column=\"id\",\n",
        "            timestamp_column=\"timestamp\",\n",
        "            target=\"target\"\n",
        "        )\n",
        "        \n",
        "        print(f\"‚úì Pr√©dictions multivari√©es g√©n√©r√©es!\")\n",
        "        print(f\"  - Shape: {predictions_multi.shape}\")\n",
        "        print(f\"\\nAper√ßu:\")\n",
        "        print(predictions_multi.head(15))\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Aucune colonne valide s√©lectionn√©e pour la pr√©diction multivari√©e\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 4: Utiliser des covariables pour am√©liorer les pr√©dictions\n",
        "print(\"=== EXEMPLE 4: PR√âDICTION AVEC COVARIABLES ===\\n\")\n",
        "\n",
        "# Dans cet exemple, on pr√©dit une colonne cible en utilisant d'autres colonnes comme covariables\n",
        "target_with_covariates = 'gdp'  # Colonne √† pr√©dire\n",
        "\n",
        "# Choisir des covariables (colonnes qui peuvent aider √† pr√©dire la cible)\n",
        "# Exemple: utiliser investment, production_kg, etc. comme covariables\n",
        "potential_covariates = ['investment', 'production_kg', 'capacityutil_kg', 'confidence_kg']\n",
        "covariates_to_use = [col for col in potential_covariates if col in df.columns and col != target_with_covariates]\n",
        "\n",
        "print(f\"Colonne cible: {target_with_covariates}\")\n",
        "print(f\"Covariables s√©lectionn√©es: {covariates_to_use}\\n\")\n",
        "\n",
        "try:\n",
        "    # Pr√©parer les donn√©es avec covariables\n",
        "    context_df_cov, _, _ = prepare_data_for_chronos2(\n",
        "        df=df,\n",
        "        date_column='date',\n",
        "        target_columns=target_with_covariates,\n",
        "        covariate_columns=covariates_to_use,\n",
        "        id_value='ecb_with_covariates',\n",
        "        freq=None\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úì Dataset avec covariables pr√©par√©:\")\n",
        "    print(f\"  - Colonnes: {context_df_cov.columns.tolist()}\")\n",
        "    print(f\"  - Nombre de lignes: {len(context_df_cov)}\\n\")\n",
        "    \n",
        "    # Afficher un aper√ßu\n",
        "    print(\"Aper√ßu des donn√©es avec covariables:\")\n",
        "    print(context_df_cov.head(10))\n",
        "    \n",
        "    # Note: Pour utiliser les covariables dans les pr√©dictions futures,\n",
        "    # vous devrez fournir un future_df avec les valeurs futures des covariables\n",
        "    # Pour l'instant, Chronos-2 utilisera les valeurs pass√©es des covariables\n",
        "    \n",
        "    # Limiter √† 1024 car Chronos-2 recommande prediction_length <= 1024\n",
        "    prediction_length_cov = min(1024, max(12, len(context_df_cov) // 10))\n",
        "    \n",
        "    predictions_cov = pipeline.predict_df(\n",
        "        context_df_cov,\n",
        "        prediction_length=prediction_length_cov,\n",
        "        quantile_levels=[0.1, 0.5, 0.9],\n",
        "        id_column=\"id\",\n",
        "        timestamp_column=\"timestamp\",\n",
        "        target=\"target\"\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n‚úì Pr√©dictions avec covariables g√©n√©r√©es!\")\n",
        "    print(f\"  - Shape: {predictions_cov.shape}\")\n",
        "    print(f\"\\nAper√ßu des pr√©dictions:\")\n",
        "    print(predictions_cov.head(10))\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erreur: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìù Notes importantes pour votre dataset\n",
        "\n",
        "1. **Format des donn√©es**: \n",
        "   - La colonne `date` doit √™tre convertible en datetime\n",
        "   - Les colonnes num√©riques ne doivent pas avoir trop de valeurs manquantes\n",
        "\n",
        "2. **Choix de la colonne cible**:\n",
        "   - Remplacez `'gdp'` dans les exemples par la colonne que vous souhaitez pr√©dire\n",
        "   - Vous pouvez pr√©dire plusieurs colonnes en les listant dans `target_columns`\n",
        "\n",
        "3. **Covariables**:\n",
        "   - Les autres colonnes num√©riques peuvent √™tre utilis√©es comme covariables\n",
        "   - Chronos-2 utilisera automatiquement les valeurs pass√©es des covariables\n",
        "\n",
        "4. **Longueur de pr√©diction**:\n",
        "   - Ajustez `prediction_length` selon votre horizon de pr√©vision souhait√©\n",
        "   - G√©n√©ralement: 10-20% de la longueur du contexte est raisonnable\n",
        "\n",
        "5. **Valeurs manquantes**:\n",
        "   - Chronos-2 peut g√©rer certaines valeurs manquantes, mais il est recommand√©\n",
        "     de les traiter avant l'inf√©rence (interpolation, forward fill, etc.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
